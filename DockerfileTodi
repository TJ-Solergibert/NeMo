# syntax=docker/dockerfile:1-labs

# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG BASE_IMAGE=nvcr.io/nvidia/pytorch:24.05-py3
# NOTE(tj.solergibert) NeMo uses pytorch:24.02-py3 BUT 24.02 doesn't ship triton 
# NOTE(tj.solergibert) pytorch:24.07-py3 contains a regression that triggers segmentations faults at scale

FROM ${BASE_IMAGE}

ENV TRANSFORMERS_OFFLINE=0 
ENV HYDRA_FULL_ERROR=1
ENV PYTHONUNBUFFERED=1

# Install NeMo requirements
ARG TE_TAG=7d576ed25266a17a7b651f2c12e8498f67e0baea
ARG MODELOPT_VERSION=0.15.0
ARG MCORE_TAG=c7c7bc5870b2b3d1d4f50f5a07f64f0947291982
ARG APEX_TAG=810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c

# APT packages
RUN apt-get update && \
  apt-get install -y bc gdb libsox-fmt-all -y && \
  apt-get clean

WORKDIR /opt

# Copy over NeMo code
COPY ./ NeMo/

WORKDIR /opt/NeMo

RUN pip install py-cpuinfo
RUN pip install pkgconfig
RUN pip install --no-cache-dir --no-build-isolation --extra-index-url https://pypi.nvidia.com \
"transformer-engine @ git+https://github.com/NVIDIA/TransformerEngine.git@${TE_TAG}" \
"megatron_core @ git+https://github.com/TJ-Solergibert/Megatron-LM.git@${MCORE_TAG}" \
"nvidia-modelopt[torch]~=${MODELOPT_VERSION}" \
"apex @ git+https://github.com/NVIDIA/apex.git@${APEX_TAG}" \
"unstructured==0.14.9" \
"llama-index==0.10.43" \
"onnxscript @ git+https://github.com/microsoft/onnxscript" \
-r tools/ctc_segmentation/requirements.txt \
".[nlp]"

WORKDIR /opt

# Megatron Core installation
RUN git clone https://github.com/TJ-Solergibert/Megatron-LM.git && \
pushd Megatron-LM && \
git checkout ${MCORE_TAG} && \
  pushd megatron/core/datasets && \
  make && \
  popd && \
popd && \
export PYTHONPATH="${PYTHONPATH}:/opt/Megatron-LM"

# TODO(tj.solergibert) Dropping support for mamba model. triton seems to be a problem, look for version with ARM wheels OR build from source
# Mamba dependancy installation
# RUN git clone https://github.com/state-spaces/mamba.git && \
#   cd mamba && \
#   git checkout v2.0.3 && \
#   python setup.py install && \
#   cd .. && \
#   rm -rf mamba

# RUN git clone https://github.com/Dao-AILab/causal-conv1d && \
#   cd causal-conv1d && \
#   git checkout v1.2.2.post1 && \
#   python setup.py install && \
#   cd .. && \
#   rm -rf causal-conv1d

# Install NeMo
WORKDIR /opt/NeMo 
RUN bash -ex && \
  pip install --no-cache-dir --no-build-isolation ".[nlp]"

# set permission
RUN chmod 777 -R /workspace
RUN chmod 777 -R /opt

WORKDIR /workspace

ENV PYTHONPATH="${PYTHONPATH}:/opt/Megatron-LM"


# Instructions:
# 0. srun --time 02:29:59 --reservation sai-a06 -A a06 --mem 460000 --pty bash
# 1. Build image: podman build -f /users/asolergi/NeMo/DockerfileTodi -t nemo /users/asolergi/NeMo/
# 2. Export image: enroot import -o /store/swissai/a06/.NeMo/container/nemo_gdb_oct_fix.sqsh podman://localhost/nemo:latest